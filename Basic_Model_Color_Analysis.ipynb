{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DZ53Ok7ue-F",
        "outputId": "9ffe95ee-7f24-49b3-dd40-f691beda73f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch [1/10], Loss: 0.9672231755473397\n",
            "Epoch [2/10], Loss: 1.05179509926926\n",
            "Epoch [3/10], Loss: 0.9446113678542051\n",
            "Epoch [4/10], Loss: 1.062917786565694\n",
            "Epoch [5/10], Loss: 1.1100957149809056\n",
            "Epoch [6/10], Loss: 1.4247461638667367\n",
            "Epoch [7/10], Loss: 1.1072576506571337\n",
            "Epoch [8/10], Loss: 1.0114685175093738\n",
            "Epoch [9/10], Loss: 1.161357037045739\n",
            "Epoch [10/10], Loss: 1.0294747054576874\n",
            "Accuracy on test set: 0.00%\n",
            "Training complete. Model saved as facenet_model.pth\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = 'Dataset'\n",
        "\n",
        "# Custom Dataset class\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, transform=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.label_dict = {}\n",
        "        self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        subfolders = [f for f in os.listdir(self.dataset_dir) if os.path.isdir(os.path.join(self.dataset_dir, f))]\n",
        "        for idx, subfolder in enumerate(subfolders):\n",
        "            self.label_dict[idx] = subfolder\n",
        "            image_files = os.listdir(os.path.join(self.dataset_dir, subfolder))\n",
        "            for image_file in image_files:\n",
        "                self.data.append(os.path.join(self.dataset_dir, subfolder, image_file))\n",
        "                self.labels.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Triplet Loss function\n",
        "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
        "    pos_dist = (anchor - positive).pow(2).sum(1)\n",
        "    neg_dist = (anchor - negative).pow(2).sum(1)\n",
        "    loss = F.relu(pos_dist - neg_dist + margin)\n",
        "    return loss.mean()\n",
        "\n",
        "# FaceNet model\n",
        "class FaceNet(nn.Module):\n",
        "    def __init__(self, embedding_dim=128):\n",
        "        super(FaceNet, self).__init__()\n",
        "        self.base_model = models.resnet18(pretrained=True)\n",
        "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Prepare triplets\n",
        "def create_triplets(dataset, indices, num_triplets):\n",
        "    triplets = []\n",
        "    labels = [dataset.labels[i] for i in indices]\n",
        "\n",
        "    for _ in range(num_triplets):\n",
        "        anchor_label = random.choice(labels)\n",
        "        positive_label = anchor_label\n",
        "        negative_label = random.choice([label for label in labels if label != anchor_label])\n",
        "\n",
        "        anchor_indices = [i for i, label in enumerate(labels) if label == anchor_label]\n",
        "        positive_indices = [i for i, label in enumerate(labels) if label == positive_label]\n",
        "        negative_indices = [i for i, label in enumerate(labels) if label == negative_label]\n",
        "\n",
        "        anchor_idx = random.choice(anchor_indices)\n",
        "        positive_idx = random.choice(positive_indices)\n",
        "        negative_idx = random.choice(negative_indices)\n",
        "\n",
        "        triplets.append((indices[anchor_idx], indices[positive_idx], indices[negative_idx]))\n",
        "\n",
        "    return triplets\n",
        "\n",
        "# Training function\n",
        "def train_model(model, dataset, train_indices, criterion, optimizer, num_epochs=25, batch_size=32):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        triplets = create_triplets(dataset, train_indices, len(train_indices) // batch_size)\n",
        "\n",
        "        for anchor_idx, positive_idx, negative_idx in triplets:\n",
        "            anchor_img, anchor_label = dataset[anchor_idx]\n",
        "            positive_img, positive_label = dataset[positive_idx]\n",
        "            negative_img, negative_label = dataset[negative_idx]\n",
        "\n",
        "            anchor_img = anchor_img.unsqueeze(0).to(device)\n",
        "            positive_img = positive_img.unsqueeze(0).to(device)\n",
        "            negative_img = negative_img.unsqueeze(0).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            anchor_out = model(anchor_img)\n",
        "            positive_out = model(positive_img)\n",
        "            negative_out = model(negative_img)\n",
        "\n",
        "            loss = criterion(anchor_out, positive_out, negative_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(triplets)}')\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, dataset, test_indices):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for idx in test_indices:\n",
        "            img, label = dataset[idx]\n",
        "            img = img.unsqueeze(0).to(device)\n",
        "            output = model(img)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += 1\n",
        "            if predicted == label:\n",
        "                correct += 1\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Data transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load data\n",
        "dataset = FaceDataset(dataset_dir, transform=transform)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "random.shuffle(indices)\n",
        "split = int(0.2 * dataset_size)\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Initialize model, criterion and optimizer\n",
        "model = FaceNet(embedding_dim=128).to(device)\n",
        "criterion = triplet_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, dataset, train_indices, criterion, optimizer, num_epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, dataset, test_indices)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'facenet_model.pth')\n",
        "\n",
        "print(\"Training complete. Model saved as facenet_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = 'Dataset'\n",
        "\n",
        "# Custom Dataset class\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, transform=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.label_dict = {}\n",
        "        self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        subfolders = [f for f in os.listdir(self.dataset_dir) if os.path.isdir(os.path.join(self.dataset_dir, f))]\n",
        "        for idx, subfolder in enumerate(subfolders):\n",
        "            self.label_dict[idx] = subfolder\n",
        "            image_files = os.listdir(os.path.join(self.dataset_dir, subfolder))\n",
        "            for image_file in image_files:\n",
        "                self.data.append(os.path.join(self.dataset_dir, subfolder, image_file))\n",
        "                self.labels.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Triplet Loss function\n",
        "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
        "    pos_dist = (anchor - positive).pow(2).sum(1)\n",
        "    neg_dist = (anchor - negative).pow(2).sum(1)\n",
        "    loss = F.relu(pos_dist - neg_dist + margin)\n",
        "    return loss.mean()\n",
        "\n",
        "# Siamese Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_dim=128):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.base_model = models.resnet18(pretrained=True)\n",
        "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Prepare triplets\n",
        "def create_triplets(dataset, indices, num_triplets):\n",
        "    triplets = []\n",
        "    labels = [dataset.labels[i] for i in indices]\n",
        "\n",
        "    for _ in range(num_triplets):\n",
        "        anchor_label = random.choice(labels)\n",
        "        positive_label = anchor_label\n",
        "        negative_label = random.choice([label for label in labels if label != anchor_label])\n",
        "\n",
        "        anchor_indices = [i for i, label in enumerate(labels) if label == anchor_label]\n",
        "        positive_indices = [i for i, label in enumerate(labels) if label == positive_label]\n",
        "        negative_indices = [i for i, label in enumerate(labels) if label == negative_label]\n",
        "\n",
        "        anchor_idx = random.choice(anchor_indices)\n",
        "        positive_idx = random.choice(positive_indices)\n",
        "        negative_idx = random.choice(negative_indices)\n",
        "\n",
        "        triplets.append((indices[anchor_idx], indices[positive_idx], indices[negative_idx]))\n",
        "\n",
        "    return triplets\n",
        "\n",
        "# Training function\n",
        "def train_model(model, dataset, train_indices, criterion, optimizer, num_epochs=15, batch_size=32):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        triplets = create_triplets(dataset, train_indices, len(train_indices) // batch_size)\n",
        "\n",
        "        for anchor_idx, positive_idx, negative_idx in triplets:\n",
        "            anchor_img, anchor_label = dataset[anchor_idx]\n",
        "            positive_img, positive_label = dataset[positive_idx]\n",
        "            negative_img, negative_label = dataset[negative_idx]\n",
        "\n",
        "            anchor_img = anchor_img.unsqueeze(0).to(device)\n",
        "            positive_img = positive_img.unsqueeze(0).to(device)\n",
        "            negative_img = negative_img.unsqueeze(0).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            anchor_out = model(anchor_img)\n",
        "            positive_out = model(positive_img)\n",
        "            negative_out = model(negative_img)\n",
        "\n",
        "            loss = criterion(anchor_out, positive_out, negative_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(triplets)}')\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, dataset, test_indices):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for idx in test_indices:\n",
        "            img, label = dataset[idx]\n",
        "            img = img.unsqueeze(0).to(device)\n",
        "            output = model(img)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += 1\n",
        "            if predicted == label:\n",
        "                correct += 1\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Data transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load data\n",
        "dataset = FaceDataset(dataset_dir, transform=transform)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "random.shuffle(indices)\n",
        "split = int(0.2 * dataset_size)\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Initialize model, criterion and optimizer\n",
        "model = SiameseNetwork(embedding_dim=128).to(device)\n",
        "criterion = triplet_loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, dataset, train_indices, criterion, optimizer, num_epochs=15, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, dataset, test_indices)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'siamese_model.pth')\n",
        "\n",
        "print(\"Training complete. Model saved as siamese_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA3GINwq2cim",
        "outputId": "1d778a89-465c-4f4f-b362-86de547b9a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch [1/15], Loss: 1.015222733671015\n",
            "Epoch [2/15], Loss: 0.9012248123233969\n",
            "Epoch [3/15], Loss: 1.2038735638965259\n",
            "Epoch [4/15], Loss: 1.0264976295557888\n",
            "Epoch [5/15], Loss: 1.0267436341805891\n",
            "Epoch [6/15], Loss: 1.0217152563008396\n",
            "Epoch [7/15], Loss: 1.0064509768377652\n",
            "Epoch [8/15], Loss: 1.0649821121584286\n",
            "Epoch [9/15], Loss: 1.035891981287436\n",
            "Epoch [10/15], Loss: 1.0111893117427826\n",
            "Epoch [11/15], Loss: 1.173291409557516\n",
            "Epoch [12/15], Loss: 1.3129462410103192\n",
            "Epoch [13/15], Loss: 1.0827827114950528\n",
            "Epoch [14/15], Loss: 1.0325284518978812\n",
            "Epoch [15/15], Loss: 1.013532045212659\n",
            "Accuracy on test set: 0.00%\n",
            "Training complete. Model saved as siamese_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = 'Dataset'\n",
        "\n",
        "# Custom Dataset class\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, transform=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.label_dict = {}\n",
        "        self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        subfolders = [f for f in os.listdir(self.dataset_dir) if os.path.isdir(os.path.join(self.dataset_dir, f))]\n",
        "        for idx, subfolder in enumerate(subfolders):\n",
        "            self.label_dict[idx] = subfolder\n",
        "            image_files = os.listdir(os.path.join(self.dataset_dir, subfolder))\n",
        "            for image_file in image_files:\n",
        "                self.data.append(os.path.join(self.dataset_dir, subfolder, image_file))\n",
        "                self.labels.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Classification Model\n",
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ClassificationModel, self).__init__()\n",
        "        self.base_model = models.resnet18(pretrained=True)\n",
        "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=15):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader)}')\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f'Accuracy on test set: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Data transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "])\n",
        "\n",
        "# Load data\n",
        "dataset = FaceDataset(dataset_dir, transform=transform)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "random.shuffle(indices)\n",
        "split = int(0.2 * dataset_size)\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
        "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)\n",
        "\n",
        "# Initialize model, criterion and optimizer\n",
        "num_classes = len(set(dataset.labels))\n",
        "model = ClassificationModel(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'classification_model.pth')\n",
        "\n",
        "print(\"Training complete. Model saved as classification_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaMM0aSU3YnH",
        "outputId": "1b1e5670-cb5c-4f3b-fd60-22c73916ff8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 95.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.9307219033891505\n",
            "Epoch [2/10], Loss: 1.4222906204787167\n",
            "Epoch [3/10], Loss: 1.1320409070361743\n",
            "Epoch [4/10], Loss: 0.9518934732133691\n",
            "Epoch [5/10], Loss: 0.7382479845122858\n",
            "Epoch [6/10], Loss: 0.6696929017251189\n",
            "Epoch [7/10], Loss: 0.4950988512824882\n",
            "Epoch [8/10], Loss: 0.4343115006658164\n",
            "Epoch [9/10], Loss: 0.40990511361848225\n",
            "Epoch [10/10], Loss: 0.31777152029628103\n",
            "Accuracy on test set: 73.79%\n",
            "Training complete. Model saved as classification_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=0.25):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Initialize Focal Loss\n",
        "criterion_focal = FocalLoss()\n",
        "\n",
        "# Train the model with Focal Loss\n",
        "train_model(model, train_loader, criterion_focal, optimizer, num_epochs=15)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8sfD3jhEc1j",
        "outputId": "fb8afbb3-ba0d-407e-cb35-82f9fae2efb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 0.030061515217477627\n",
            "Epoch [2/15], Loss: 0.008487695157369175\n",
            "Epoch [3/15], Loss: 0.0045405383693419435\n",
            "Epoch [4/15], Loss: 0.004172254944850548\n",
            "Epoch [5/15], Loss: 0.003057711627496412\n",
            "Epoch [6/15], Loss: 0.0027775224863158987\n",
            "Epoch [7/15], Loss: 0.0024320023746068646\n",
            "Epoch [8/15], Loss: 0.0034137442170586755\n",
            "Epoch [9/15], Loss: 0.0017686971932458948\n",
            "Epoch [10/15], Loss: 0.001936071208505878\n",
            "Epoch [11/15], Loss: 0.0021383379813125266\n",
            "Epoch [12/15], Loss: 0.002047248408209932\n",
            "Epoch [13/15], Loss: 0.0015627399113162194\n",
            "Epoch [14/15], Loss: 0.0012899494082680783\n",
            "Epoch [15/15], Loss: 0.0013093628326301273\n",
            "Accuracy on test set: 83.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=-1)\n",
        "        true_dist = pred.data.clone()\n",
        "        true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return self.criterion(pred, true_dist)\n",
        "\n",
        "# Initialize Label Smoothing Loss\n",
        "criterion_label_smoothing = LabelSmoothingLoss(num_classes, smoothing=0.1)\n",
        "\n",
        "# Train the model with Label Smoothing Loss\n",
        "train_model(model, train_loader, criterion_label_smoothing, optimizer, num_epochs=15)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "3gS3XoA5EgFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9a4d3d-241b-4ef0-bba0-65b00f13069d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 0.255461624738845\n",
            "Epoch [2/15], Loss: 0.14716044000603937\n",
            "Epoch [3/15], Loss: 0.1359572805125605\n",
            "Epoch [4/15], Loss: 0.11123548617417162\n",
            "Epoch [5/15], Loss: 0.10289283968846906\n",
            "Epoch [6/15], Loss: 0.0860254265029322\n",
            "Epoch [7/15], Loss: 0.06575526686554606\n",
            "Epoch [8/15], Loss: 0.05750623061745004\n",
            "Epoch [9/15], Loss: 0.04504436779428612\n",
            "Epoch [10/15], Loss: 0.04200073780322617\n",
            "Epoch [11/15], Loss: 0.035760038447650994\n",
            "Epoch [12/15], Loss: 0.04096733308820562\n",
            "Epoch [13/15], Loss: 0.036847452336752955\n",
            "Epoch [14/15], Loss: 0.05241543583741242\n",
            "Epoch [15/15], Loss: 0.0771996345879002\n",
            "Accuracy on test set: 82.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Using Focal Loss\n",
        "# criterion = FocalLoss()\n",
        "\n",
        "# Using Label Smoothing Loss\n",
        "# criterion = LabelSmoothingLoss(num_classes, smoothing=0.1)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=15)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "XY0DRsNkEi2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8030710b-71ef-445b-a546-e5944c89b8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 0.06814385099675167\n",
            "Epoch [2/15], Loss: 0.6617035906423222\n",
            "Epoch [3/15], Loss: 0.7528125867247581\n",
            "Epoch [4/15], Loss: 0.5073415616696532\n",
            "Epoch [5/15], Loss: 0.33842935430055315\n",
            "Epoch [6/15], Loss: 0.23729107782922007\n",
            "Epoch [7/15], Loss: 0.14329142788086424\n",
            "Epoch [8/15], Loss: 0.11036824316463688\n",
            "Epoch [9/15], Loss: 0.08659483543173833\n",
            "Epoch [10/15], Loss: 0.139278515284373\n",
            "Epoch [11/15], Loss: 0.1230071563358334\n",
            "Epoch [12/15], Loss: 0.13822178161618384\n",
            "Epoch [13/15], Loss: 0.11222686830230734\n",
            "Epoch [14/15], Loss: 0.12000984958881004\n",
            "Epoch [15/15], Loss: 0.11160592554899101\n",
            "Accuracy on test set: 78.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQMSa_s2PQmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}